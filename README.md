# Large_Model_Project_Collection
这个 repository 用于收集整理学习大模型时阅读的文档（论文、技术报告和网页）。

此 `md` 文件只展示文档标题；但是在 repository 中会放置**自己标注过的**论文或技术报告。

另外，这个 repository 中还会放置一些自己记录的笔记。

Let's enjoy the power of large models~

---

## Transformer 基础

1. Attention Is All You Need

## 预训练大模型

1. Improving Language Understanding by Generative Pre-Training (GPT-1)
2. Language Models are Unsupervised Multitask Learners (GPT-2)
3. Language Models are Few-Shot Learners (GPT-3)

## 提示学习/工程

1. Structured Chain-of-Thought Prompting for Code Generation (CoT + Software Engineering)

## RAG

## 微调大模型

## 微调技术

1. Instruction Tuning for Large Language Models: A Survey

## 偏好对齐技术

## 大模型 benchmark 数据集和评估指标

1. BLEU: a Method for Automatic Evaluation of Machine Translation

## 外部联系

1. Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods (LLM + RL)

## 自己的

1. 干货_深度神经网络中的计算和内存带宽
2. 干货_深度学习模型训练的批量大小与GPU内存之间的关系

## Github 的在线资源
